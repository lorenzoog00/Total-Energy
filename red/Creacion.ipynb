{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí se juntarán todos los csvs generados previamente, se llevará a cabo una limpieza y como resultado se espera un csv limpio con todos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from joblib import dump\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Juntando todos los archivos en uno solo que se llama AllData.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] El sistema no puede encontrar la ruta especificada: '../../data/excel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m directory_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../data/excel\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Encontrar todos los archivos CSV en el directorio\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m csv_files \u001b[38;5;241m=\u001b[39m [file \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Lista para guardar los datos de todos los archivos CSV\u001b[39;00m\n\u001b[0;32m      7\u001b[0m all_data_frames \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] El sistema no puede encontrar la ruta especificada: '../../data/excel'"
     ]
    }
   ],
   "source": [
    "directory_path = '../../data/excel'\n",
    "\n",
    "# Encontrar todos los archivos CSV en el directorio\n",
    "csv_files = [file for file in os.listdir(directory_path) if file.endswith('Data.csv')]\n",
    "\n",
    "# Lista para guardar los datos de todos los archivos CSV\n",
    "all_data_frames = []\n",
    "\n",
    "# Leer cada archivo CSV y agregarlo a la lista\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(directory_path, csv_file)\n",
    "    data_frame = pd.read_csv(file_path)\n",
    "    all_data_frames.append(data_frame)\n",
    "\n",
    "# Combinar todos los DataFrames en uno solo\n",
    "all_data_combined = pd.concat(all_data_frames, ignore_index=True)\n",
    "\n",
    "# Guardar el DataFrame combinado en un nuevo archivo CSV\n",
    "combined_csv_path = os.path.join(directory_path, 'AllData.csv')\n",
    "all_data_combined.to_csv(combined_csv_path, index=False)\n",
    "\n",
    "print(f'Todos los archivos han sido combinados y guardados en {combined_csv_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de renglones sin 'Total Energy': 44\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV en un DataFrame de pandas\n",
    "# Reemplaza 'path_to_your_csv.csv' con la ruta real al archivo CSV que deseas analizar\n",
    "csv_path = '../data/excel/AllData.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Contamos el número de filas donde la columna 'Total Energy (Ry)' tiene valores nulos o vacíos\n",
    "missing_energy_count = df['Total Energy (Ry)'].isnull().sum()\n",
    "print(f\"Numero de renglones sin 'Total Energy': {missing_energy_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminando los datos que no tienen energía total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las filas donde 'Total Energy (Ry)' es nulo o vacío\n",
    "df = df.dropna(subset=['Total Energy (Ry)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de renglones sin 'Total Energy': 0\n"
     ]
    }
   ],
   "source": [
    "missing_energy_count = df['Total Energy (Ry)'].isnull().sum()\n",
    "print(f\"Numero de renglones sin 'Total Energy': {missing_energy_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar la columna 'Archivo'\n",
    "cleanDF = df.drop('Archivo', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convirtiendo Total energy a float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Total Energy (Ry)' to float\n",
    "cleanDF['Total Energy (Ry)'] = pd.to_numeric(cleanDF['Total Energy (Ry)'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows that could not be converted to float (e.g., containing non-numeric strings)\n",
    "cleanDF = cleanDF.dropna(subset=['Total Energy (Ry)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Elemento              object\n",
       "Ecut                   int64\n",
       "KPoints               object\n",
       "Pseudopotencial       object\n",
       "Total Energy (Ry)    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanDF.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Especificando que columnas de entrada son de que tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the numerical and categorical columns\n",
    "numerical_cols = ['Ecut']  # the numerical column\n",
    "categorical_cols = cleanDF.columns.drop(['Ecut', 'Total Energy (Ry)'])  # all   other columns are categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tipo de Scaler que se usará para cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating transformers for the numerical and categorical data\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muy buena herramienta porque transforma diferentes columnas dependiendo la necesidad de cada uno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a preprocessor with ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-setup preprocessing and transformation\n",
    "# Assume preprocessor is already defined and includes scaling for 'ecut' and one-hot encoding for categorical columns\n",
    "X = cleanDF.drop('Total Energy (Ry)', axis=1)\n",
    "y = cleanDF['Total Energy (Ry)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = preprocessor.fit_transform(X)  # Re-fit the preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a preprocessing and training pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividiendo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data types to float32 for neural network processing\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneHotEncoder se usa para pasar a numeros las columnas string. Crea una columna nueva para cada string nuevo, por eso hay tantas columnas de input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas de input: 46\n"
     ]
    }
   ],
   "source": [
    "# Model configuration\n",
    "input_dim = X_train.shape[1]  # Number of features\n",
    "print(f'Columnas de input: {input_dim}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arquitectura de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(input_dim,)),  # First hidden layer\n",
    "    Dense(64, activation='relu'), \n",
    "    Dense(1, activation='linear')  # Output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intentando con la función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "def train_until_mae_below_threshold_enhanced(X_train, y_train, X_test, y_test, initial_config, threshold=0.05):\n",
    "    # Initialize training parameters\n",
    "    config = initial_config.copy()\n",
    "    best_mae = float('inf')  # Track best MAE\n",
    "    log_path = \"training_log.txt\"\n",
    "\n",
    "    # Open the log file\n",
    "    with open(log_path, \"w\") as log_file:\n",
    "        log_file.write(\"Training Start Time: {}\\n\".format(datetime.datetime.now()))\n",
    "        \n",
    "        # Possible activation functions to cycle through\n",
    "        activations = ['relu', 'sigmoid', 'relu']\n",
    "        \n",
    "        while True:\n",
    "            # Create model with dynamic activations\n",
    "            model = Sequential([\n",
    "                Dense(config['neurons'][0], activation=activations[0], input_shape=(X_train.shape[1],)),\n",
    "                Dense(config['neurons'][1], activation=activations[1]),\n",
    "                Dense(1, activation='linear')\n",
    "            ])\n",
    "            model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "            \n",
    "            # Early stopping\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "            \n",
    "            # Fit model\n",
    "            history = model.fit(X_train, y_train, epochs=100, batch_size=config['batch_size'], validation_split=config['val_split'], verbose=0, callbacks=[early_stopping])\n",
    "            \n",
    "            # Predict and evaluate\n",
    "            y_pred = model.predict(X_test)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            log_file.write(\"Config: {}, MAE: {}\\n\".format(config, mae))\n",
    "            \n",
    "            if mae < best_mae:\n",
    "                best_mae = mae\n",
    "                best_model_path = \"best_model.h5\"\n",
    "                model.save(best_model_path)\n",
    "                print('NEW BEST MODEL SAVED with mae:' + str(mae))\n",
    "                log_file.write(\"New best model saved with MAE: {} at {}\\n\".format(best_mae, best_model_path))\n",
    "            \n",
    "            # Check if the MAE threshold is met\n",
    "            if mae < threshold:\n",
    "                break\n",
    "            \n",
    "            # Adjust parameters if needed\n",
    "            # Cycle activations\n",
    "            activations = activations[1:] + activations[:1]\n",
    "            \n",
    "            # Increase neurons\n",
    "            config['neurons'] = [n + 8 for n in config['neurons']]\n",
    "            \n",
    "            # Adjust validation split\n",
    "            config['val_split'] = random.uniform(0.2,0.01)\n",
    "            \n",
    "            # Adjust batch size\n",
    "            config['batch_size'] = random.randint(10,33)\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW BEST MODEL SAVED with mae:181.74022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW BEST MODEL SAVED with mae:1.9510807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW BEST MODEL SAVED with mae:1.2786696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW BEST MODEL SAVED with mae:0.66799223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW BEST MODEL SAVED with mae:0.41078788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m initial_config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneurons\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m16\u001b[39m],\n\u001b[0;32m      4\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_split\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.02\u001b[39m,\n\u001b[0;32m      5\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m32\u001b[39m\n\u001b[0;32m      6\u001b[0m  }\n\u001b[1;32m----> 7\u001b[0m model, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_until_mae_below_threshold_enhanced\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[95], line 31\u001b[0m, in \u001b[0;36mtrain_until_mae_below_threshold_enhanced\u001b[1;34m(X_train, y_train, X_test, y_test, initial_config, threshold)\u001b[0m\n\u001b[0;32m     28\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Fit model\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_split\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Predict and evaluate\u001b[39;00m\n\u001b[0;32m     34\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:355\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_epoch_iterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[0;32m    346\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m    347\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    353\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    354\u001b[0m     )\n\u001b[1;32m--> 355\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    367\u001b[0m }\n\u001b[0;32m    368\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:439\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m--> 439\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menumerate_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_test_batch_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:660\u001b[0m, in \u001b[0;36mTFEpochIterator.enumerate_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    658\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_iterator\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 660\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    661\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches:\n\u001b[0;32m    662\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\n\u001b[0;32m    663\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution\n\u001b[0;32m    664\u001b[0m         ):\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:501\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[0;32m    500\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:705\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    701\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    703\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    704\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 705\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:744\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    741\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[0;32m    742\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[0;32m    743\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[1;32m--> 744\u001b[0m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3478\u001b[0m, in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   3477\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3478\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3479\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3481\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "initial_config = {\n",
    "     'neurons': [32, 16],\n",
    "     'val_split': 0.02,\n",
    "     'batch_size': 32\n",
    " }\n",
    "model, history = train_until_mae_below_threshold_enhanced(X_train, y_train, X_test, y_test, initial_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tipo de compilación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 251.5390 - val_loss: 101.3258\n",
      "Epoch 2/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96.4237 - val_loss: 40.6118\n",
      "Epoch 3/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 28.8908 - val_loss: 4.4121\n",
      "Epoch 4/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.4115 - val_loss: 3.8885\n",
      "Epoch 5/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.2434 - val_loss: 3.8853\n",
      "Epoch 6/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.7807 - val_loss: 3.7542\n",
      "Epoch 7/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.9126 - val_loss: 3.3928\n",
      "Epoch 8/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.7211 - val_loss: 3.3150\n",
      "Epoch 9/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.8448 - val_loss: 3.2161\n",
      "Epoch 10/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.8758 - val_loss: 3.1420\n",
      "Epoch 11/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.3813 - val_loss: 3.4039\n",
      "Epoch 12/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.9548 - val_loss: 2.7308\n",
      "Epoch 13/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.5103 - val_loss: 2.9670\n",
      "Epoch 14/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.8329 - val_loss: 3.7490\n",
      "Epoch 15/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.3456 - val_loss: 3.2426\n",
      "Epoch 16/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.6027 - val_loss: 3.5932\n",
      "Epoch 17/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.3304 - val_loss: 3.0932\n",
      "Epoch 18/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.2828 - val_loss: 3.0448\n",
      "Epoch 19/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.3611 - val_loss: 3.4989\n",
      "Epoch 20/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.3610 - val_loss: 2.3426\n",
      "Epoch 21/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.1487 - val_loss: 2.5268\n",
      "Epoch 22/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.1735 - val_loss: 2.2345\n",
      "Epoch 23/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.0919 - val_loss: 2.2084\n",
      "Epoch 24/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9141 - val_loss: 2.0322\n",
      "Epoch 25/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.0566 - val_loss: 2.7866\n",
      "Epoch 26/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9017 - val_loss: 2.2105\n",
      "Epoch 27/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9250 - val_loss: 2.0770\n",
      "Epoch 28/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.8272 - val_loss: 1.7268\n",
      "Epoch 29/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.7432 - val_loss: 1.8328\n",
      "Epoch 30/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.7001 - val_loss: 2.1106\n",
      "Epoch 31/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9848 - val_loss: 1.9905\n",
      "Epoch 32/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.8417 - val_loss: 2.0121\n",
      "Epoch 33/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6686 - val_loss: 1.7809\n",
      "Epoch 34/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6925 - val_loss: 2.4496\n",
      "Epoch 35/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.7460 - val_loss: 1.8239\n",
      "Epoch 36/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5645 - val_loss: 1.8746\n",
      "Epoch 37/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6422 - val_loss: 1.8150\n",
      "Epoch 38/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4622 - val_loss: 2.1176\n",
      "Epoch 39/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.8644 - val_loss: 1.6655\n",
      "Epoch 40/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6423 - val_loss: 1.5403\n",
      "Epoch 41/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.7069 - val_loss: 1.5172\n",
      "Epoch 42/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4872 - val_loss: 1.6866\n",
      "Epoch 43/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3368 - val_loss: 1.7965\n",
      "Epoch 44/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4918 - val_loss: 1.5890\n",
      "Epoch 45/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3562 - val_loss: 1.6085\n",
      "Epoch 46/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3269 - val_loss: 1.9763\n",
      "Epoch 47/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3746 - val_loss: 1.2189\n",
      "Epoch 48/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3462 - val_loss: 1.2730\n",
      "Epoch 49/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3889 - val_loss: 1.7830\n",
      "Epoch 50/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2495 - val_loss: 1.2112\n",
      "Epoch 51/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2605 - val_loss: 1.3023\n",
      "Epoch 52/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2494 - val_loss: 1.3164\n",
      "Epoch 53/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1839 - val_loss: 1.3349\n",
      "Epoch 54/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3296 - val_loss: 1.3551\n",
      "Epoch 55/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3195 - val_loss: 2.7115\n",
      "Epoch 56/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5713 - val_loss: 2.1196\n",
      "Epoch 57/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3932 - val_loss: 1.5946\n",
      "Epoch 58/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3030 - val_loss: 1.1616\n",
      "Epoch 59/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2057 - val_loss: 1.1692\n",
      "Epoch 60/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1887 - val_loss: 1.3456\n",
      "Epoch 61/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1694 - val_loss: 1.6786\n",
      "Epoch 62/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3318 - val_loss: 1.1485\n",
      "Epoch 63/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1921 - val_loss: 1.4117\n",
      "Epoch 64/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2774 - val_loss: 1.3808\n",
      "Epoch 65/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1440 - val_loss: 1.0212\n",
      "Epoch 66/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2808 - val_loss: 1.0970\n",
      "Epoch 67/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1547 - val_loss: 1.3100\n",
      "Epoch 68/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1825 - val_loss: 0.9934\n",
      "Epoch 69/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1347 - val_loss: 1.2336\n",
      "Epoch 70/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2484 - val_loss: 1.1785\n",
      "Epoch 71/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2757 - val_loss: 1.5978\n",
      "Epoch 72/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3568 - val_loss: 1.0369\n",
      "Epoch 73/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2274 - val_loss: 1.2947\n",
      "Epoch 74/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3551 - val_loss: 1.5391\n",
      "Epoch 75/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2417 - val_loss: 1.3369\n",
      "Epoch 76/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1078 - val_loss: 1.0850\n",
      "Epoch 77/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1447 - val_loss: 1.3038\n",
      "Epoch 78/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1257 - val_loss: 1.0986\n",
      "Epoch 79/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2044 - val_loss: 1.1544\n",
      "Epoch 80/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2938 - val_loss: 1.1968\n",
      "Epoch 81/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0737 - val_loss: 1.5313\n",
      "Epoch 82/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0819 - val_loss: 1.4229\n",
      "Epoch 83/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2233 - val_loss: 1.3475\n",
      "Epoch 84/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3093 - val_loss: 1.4270\n",
      "Epoch 85/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1582 - val_loss: 0.9730\n",
      "Epoch 86/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1322 - val_loss: 1.2858\n",
      "Epoch 87/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1194 - val_loss: 1.3383\n",
      "Epoch 88/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2663 - val_loss: 0.9248\n",
      "Epoch 89/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1339 - val_loss: 0.9596\n",
      "Epoch 90/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1361 - val_loss: 1.1636\n",
      "Epoch 91/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1849 - val_loss: 1.1342\n",
      "Epoch 92/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1182 - val_loss: 0.8680\n",
      "Epoch 93/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1906 - val_loss: 2.2570\n",
      "Epoch 94/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2427 - val_loss: 1.8483\n",
      "Epoch 95/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2370 - val_loss: 0.9979\n",
      "Epoch 96/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2421 - val_loss: 1.2775\n",
      "Epoch 97/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0577 - val_loss: 1.1710\n",
      "Epoch 98/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1787 - val_loss: 1.0719\n",
      "Epoch 99/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1254 - val_loss: 0.9640\n",
      "Epoch 100/100\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2175 - val_loss: 1.0722\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=16, validation_split=0.02, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming history is returned by model.fit\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the training and validation loss\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')  # 'bo' gives us blue dot\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')  # 'b' gives us a solid blue line\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0, 20)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9301 \n",
      "Test Loss: 0.9160410165786743\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R cuadrado (R2): un R² de 1,00 es perfecto.\n",
    "\n",
    "Error cuadrático medio (MSE): un MSE de 0,81 indica que, en promedio, la diferencia al cuadrado entre los valores previstos y reales es menor que 1.\n",
    "\n",
    "Error absoluto medio (MAE): un MAE de 0,61 sugiere que, en promedio la distancia hacia el objetivo.\n",
    "\n",
    "Error cuadrático medio (RMSE): el valor RMSE de 0,90, que es la raíz cuadrada del MSE, suele ser más útil que el MSE para comprender el error promedio porque está en las mismas unidades que la variable objetivo. El hecho de que esté cerca del MAE sugiere que no hay muchos errores grandes que sesguen significativamente la media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "R-squared (R2): 1.00\n",
      "Mean Squared Error (MSE): 1.82\n",
      "Mean Absolute Error (MAE): 0.92\n",
      "Root Mean Squared Error (RMSE): 1.35\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the metrics\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Print the metrics\n",
    "print(f'R-squared (R2): {r2:.2f}')\n",
    "print(f'Mean Squared Error (MSE): {mse:.2f}')\n",
    "print(f'Mean Absolute Error (MAE): {mae:.6f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardando el preprocessor y el modelo de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pipeline.joblib']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(pipeline.named_steps['preprocessor'], 'preprocessor.joblib')\n",
    "model.save('my_model2.h5')\n",
    "dump(pipeline, 'pipeline.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
